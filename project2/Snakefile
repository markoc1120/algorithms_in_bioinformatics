rule all:
    input:
        "results/report.pdf"

rule run_benchmark:
    output:
        figure="results/benchmark/alignment_performance.png"
    conda:
        "environment.yml"
    shell:
        "python scripts/benchmark.py --output-path {output.figure}"

rule generate_benchmark_section:
    input:
        "results/benchmark/alignment_performance.png"
    output:
        "sections/benchmark.md"
    shell:
        'echo -e "![Benchmark Results]({input})\n" > {output}'

rule generate_answers_section:
    input:
        sequences="data/sequences.fasta"
    output:
        answers="sections/test_answers.md"
    conda:
        "environment.yml"
    shell:
        "python scripts/answers.py {input.sequences} > {output.answers}"

rule merge_report:
    input:
        benchmark="sections/benchmark.md",
        answers="sections/test_answers.md",
        sections=["sections/introduction.md",
                 "sections/methods.md",
                 "sections/test.md",
                 "sections/test_answers.md",
                 "sections/experiments.md",
                 "sections/benchmark.md"]
    output:
        report="results/report.pdf"
    shell:
        "pandoc {input.sections} -o {output.report}"
